{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Download and untar the XSUM dataset \n",
    "! wget http://bollin.inf.ed.ac.uk/public/direct/XSUM-EMNLP18-Summary-Data-Original.tar.gz\n",
    "! tar -xf XSUM-EMNLP18-Summary-Data-Original.tar.gz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os, io, boto3, sagemaker\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "session = sagemaker.Session()\n",
    "session_bucket = session.default_bucket()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Extract every summary and text body from the downloaded files \n",
    "summaries = []\n",
    "bodies = []\n",
    "\n",
    "for filename in tqdm(os.listdir('./bbc-summary-data')):\n",
    "    with open(f'./bbc-summary-data/{filename}') as h: \n",
    "        data = h.readlines()\n",
    "        end_of_file = len(data)\n",
    "        \n",
    "        i = 0        \n",
    "        while i < end_of_file:\n",
    "            \n",
    "            if data[i] == '[SN]FIRST-SENTENCE[SN]\\n':\n",
    "                i += 1\n",
    "                new_summary = ''\n",
    "                while data[i] != '\\n':\n",
    "                    new_summary += f'{data[i].strip()} '\n",
    "                    i += 1\n",
    "                summaries.append(new_summary)\n",
    "                \n",
    "            elif data[i] == '[SN]RESTBODY[SN]\\n':\n",
    "                i += 1\n",
    "                new_body = ''\n",
    "                while i != end_of_file - 1:\n",
    "                    new_body += f'{data[i].strip()} '\n",
    "                    i += 1\n",
    "                bodies.append(new_body)\n",
    "            \n",
    "            i += 1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 237018/237018 [01:33<00:00, 2524.89it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Create DataFrame, clean all missing text bodies / summaries\n",
    "df = pd.DataFrame({'text':bodies,'summary':summaries})\n",
    "raw_size = len(df.index)\n",
    "\n",
    "df.replace(\"\",float(\"NaN\"),inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(f'Deleted {raw_size-len(df.index)} empty samples')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deleted 395 empty samples\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Split into train/validation datasets\n",
    "train_df, validation_df = train_test_split(df,test_size=0.15,random_state=7)\n",
    "\n",
    "train_df.name = 'train'\n",
    "validation_df.name = 'validation'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Take a look at the layout of the DataFrame \n",
    "train_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76618</th>\n",
       "      <td>Rail, Maritime and Transport union (RMT) membe...</td>\n",
       "      <td>Possible strike action could disrupt Caledonia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232137</th>\n",
       "      <td>The vote in favour - by 46 out of 81 MPs - pav...</td>\n",
       "      <td>Montenegro's parliament has ratified the count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18091</th>\n",
       "      <td>While National Museum Wales can thank the rema...</td>\n",
       "      <td>The richness of an art gallery's collection is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186450</th>\n",
       "      <td>Media playback is unsupported on your device 3...</td>\n",
       "      <td>A video showing SNP councillors burning a copy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83850</th>\n",
       "      <td>23 September 2016 Last updated at 14:12 BST It...</td>\n",
       "      <td>Scientists are trying to help save coral reefs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "76618   Rail, Maritime and Transport union (RMT) membe...   \n",
       "232137  The vote in favour - by 46 out of 81 MPs - pav...   \n",
       "18091   While National Museum Wales can thank the rema...   \n",
       "186450  Media playback is unsupported on your device 3...   \n",
       "83850   23 September 2016 Last updated at 14:12 BST It...   \n",
       "\n",
       "                                                  summary  \n",
       "76618   Possible strike action could disrupt Caledonia...  \n",
       "232137  Montenegro's parliament has ratified the count...  \n",
       "18091   The richness of an art gallery's collection is...  \n",
       "186450  A video showing SNP councillors burning a copy...  \n",
       "83850   Scientists are trying to help save coral reefs...  "
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Take a look at a full example\n",
    "print(f'BODY: {train_df.text[10]}\\n\\n')\n",
    "print(f'SUMMARY: {train_df.summary[10]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BODY: Romanian tourist Andreea Cristea, 29, was in London with partner Andrei Burnaz to celebrate his birthday, when she was hurled into the Thames. She remains unconscious in a London hospital, the Romanian ambassador, Dan Mihalache, told BBC News. He described her condition as \"stable, but in a good direction\". \"It's a miracle she survived\", he told BBC News on Friday. \"She was practically thrown into the Thames.\" Mr Mihalache said he thought the attacker's car mounted the pavement and hit Mr Burnaz first, before pushing Ms Cristea into the Thames. \"That's quite dramatic\", he said. \"We hope that all will be okay. In the end she survived, she was strong enough.\" It was previously not known whether she jumped to escape the car or was hit and hurled into the water. After being rescued from the water, Ms Cristea had an operation for a blood clot on her brain while Mr Burnaz sustained a broken foot. Her family, who are now in London, have asked for privacy as she recovers and Mr Mihalache said he would not issue more statements on their behalf. \n",
      "\n",
      "\n",
      "SUMMARY: The woman pushed from Westminster Bridge during Wednesday's attack was due to receive a marriage proposal the same day, the BBC has learned. \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# Write dataframe to a buffer in CSV format, and upload it to S3 \n",
    "for df in [train_df, validation_df]:\n",
    "    buffer = io.StringIO()\n",
    "    df.to_csv(buffer, index=False)\n",
    "    s3_resource.Object(session_bucket,f'xsum-dataset/{df.name}.csv').put(Body=buffer.getvalue())"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "307046d30e874e46db951879b0020d70d35a4b804063ea90c901d429d46450f7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('testSam': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}